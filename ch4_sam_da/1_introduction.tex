\section{Introduction}
\label{sec:samda_introduction}

Domain adaptation for semantic segmentation in medical imaging is vital to ensure that models perform effectively across different domains (\eg, different medical centers or different scanning protocols). This is critical for the practical deployment of these models in real-world medical settings where training data is often collected over a limited number of sites or settings but needs to generalize broadly. In the context of medical imaging, two domain adaptation settings are particularly interesting: (1) {\it fully supervised}, where a general model is fine-tuned with source domain images and annotations in the hope it generalizes to a target domain, and (2) {\it test-time adaptation} whereby a single target domain image is available to fine-tune a general model. While the former case needs to generalize the model to other domains via fine-tuning, the latter adapts the general model to a specific test time case. In this paper, we consider both cases. 

\textfig[t]{1}{Figures/datasets.pdf}{Predictions of the proposed method on three of the four studied datasets: Retouch\cite{retouch}, MRI\cite{mri_dataset}, and HQSeg-44k\cite{ke2024segment}. For the medical datasets, we show the training domain on the top row and a different domain on the bottom (Specralis and Cirrus for Retouch, BMC and UCL for MRI). For HQSeg-44k, both images come from HRSOD\cite{hrsod_zeng2019towards}.
}{fig:samda_datasets}

At the same time, recent foundational segmentation models, such as Segment Anything Model (SAM)\sidecite{sam} or Segment-Everything-Everywhere Model (SEEM)\sidecite{zou2024segment}, accept prompts of different input types to yield impressive zero-shot segmentation performance. Despite their capabilities on natural images, they fail to demonstrate similar prowess with medical domain images\sidecite{zhang2023comprehensive}. 
However, recent works have attempted to address this by fine-tuning models end-to-end, for instance,\sidecite{MedSAM,zhang2023customized} fully fine-tuned the model for 3D medical data, which led to high computational and memory costs, while only adding marginal benefits when training from natural image based pre-trained models\sidecite{raghu2019transfusion,zamir2018taskonomy}. Regardless, such strategies only offer temporary workarounds as increased model complexity and training data sizes suggest that end-to-end training may only be feasible for entities with ample resources.

In response to this challenge, we have witnessed the emergence of Parameter Efficient Fine-Tuning (PEFT) methods. These techniques aim to minimize the number of trainable parameters while achieving comparable performance to full fine-tuning\sidecite{xu2023parameter,hu2022lora,pfeiffer2020adapterfusion,mahabadi2021parameter,lin2020exploring}. Originally developed within the domain of Natural Language Processing (NLP), these techniques are now experiencing rapid evolution, driven by the emergence of increasingly large language models. This trend is fueled by the impractical training times associated with these larger models, necessitating more efficient fine-tuning strategies\sidecite{li2021prefix,liu2023gpt,he2021towards}. 

Another aspect of medical data lies in its variety of domains stemming from the vast diversity of acquisition protocols and devices. It remains uncertain whether a model trained on specific device settings will exhibit comparable performance on a different domain, even when confronted with the same image modality. Therefore, developing a model capable of generalizing over unseen domains is invaluable, not only for practical reasons but also because retraining a model on a different domain would necessitate further certification of the new model. In this line, recent efforts have been devoted to Test-Time Domain Adaptation for semantic segmentation\sidecite{janouskova2023single,wang2023dynamically}, a scenario in which a trained model is fine-tuned for a single sample. 

We propose a novel SAM adapter that offers excellent and broad generalization capabilities due to its strategic placement in the mask decoder while simultaneously yielding improved segmentation across both fully supervised and test-time domain adaptation tasks. Our adapter is simple in nature and leverages the pre-trained model that inherently contains domain knowledge. Consequently, neither the image encoder nor the mask decoder require significant parameter updates during the adaptation phase. By making this design choice, we significantly decrease the number of trainable parameters compared to existing methods, making it highly efficient and easy to train. We extensively validate our approach across three medical datasets and one natural image dataset. In addition, we provide comprehensive ablation studies that explore the impact of our design choices. Our results demonstrate that the SAM Decoder Adapter (SAM-DA) outperforms general methods such as LoRA\sidecite{hu2022lora} and HQ-SAM\sidecite{ke2024segment}, and also medical-specific methods (\eg~ Med-SA\sidecite{wu2023medical}) on both fully supervised segmentation and test-time domain adaptation. Particularly noteworthy is that this superior performance is achieved by training less than $1\%$ of the total SAM parameters.

Our contributions can be summarized as follows:
\begin{itemize}
    \item We propose an adapter for SAM based on previous LLM literature. We position it in the decoder, significantly reducing parameters and training time.
    \item We validate our setting on two tasks: domain generalization and test-time domain adaptation. 
    \item Our experiments show that the proposed adapter achieves better generalization than other encoder-focused PEFT methods. 
\end{itemize}

% An enticing alternative are Parameter Efficient Fine-Tuning methods that minimize the number of trainable parameters while achieving comparable performances to full fine-tuning\sidecite{hu2022lora,lin2020exploring,mahabadi2021parameter,pfeiffer2020adapterfusion}. Originally developed within the domain of Natural Language Processing (NLP), these techniques are extending to image segmentation\sidecite{chen2023sam,chen2022vision}, fueled by impractical training times associated with Large Language Models (LLM)\sidecite{he2021towards,li2021prefix}. For instance, Medical SAM Adapter\sidecite{wu2023medical} proposes three methods in increasing complexity: (i) incorporate a traditional adapter into the image encoder, (ii) extend the adapter functionality to accommodate 3D images by duplicating certain layers, and (iii) a prompt-conditioned adaptation approach. With significantly smaller decoder models, current efforts are primarily focused on adapting the model's encoder weights. In contrast,\sidecite{ke2024segment} proposes to improve the SAM segmentation quality via a learnable High-Quality Output Token injected into SAM's decoder that receives intermediate features from the ViT image encoder. However, little has been shown regarding the effect of performing decoder adaptation. This lies at the heart of the present work. 

% We propose a novel SAM adapter that offers excellent and broad generalization capabilities due to its strategic placement in the mask decoder while simultaneously yielding improved segmentation across both fully supervised and test-time domain adaptation tasks. Our adapter is simple in nature and leverages the pre-trained model that inherently contains domain knowledge.
% Consequently, neither the image encoder nor the mask decoder require significant parameter updates during the adaptation phase. By making this design choice, we significantly decrease the number of trainable parameters compared to existing methods, making it highly efficient and easy to train. We extensively validate our approach across three medical datasets and one natural image dataset. In addition, we provide comprehensive ablation studies that explore the impact of our design choices. Our results demonstrate that the SAM Decoder Adapter (SAM-DA) outperforms general methods such as LoRA\sidecite{hu2022lora} and HQ-SAM\sidecite{ke2024segment}, and also medical-specific methods (\eg~ Med-SA\sidecite{wu2023medical}) on both fully supervised segmentation and test-time domain adaptation. Particularly noteworthy is that this superior performance is achieved by training less than $1\%$ of the total SAM parameters.
