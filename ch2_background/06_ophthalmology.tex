% Elements of Ophthalmology
%   Imaging the Retina --> technical stuff on how OCTs work and what we can get. Also fundus
%   Seeing in an OCT --> diseases that can be seen, concept of biomarker
%   Evaluating Vision: The ETDRS Grid --> Just talk about it
%   Merging DL and Ophthalmology --> How and why you would put these two together (a lot of images, difficult to segment...)

\section{Elements of Ophthalmology}
\label{sec:ophthalmology}

\textfig[t]{0.75}{Figures/retina-structure.jpg}{Light enters the eye through the cornea and projects on the retina, where rods and cones transform it into electrical impulses that travel ventrally to the optic nerve through horizontal, bipolar, amacrine and ganglion cells. Image taken from \cite{layers2016retina}}{fig:eye}

The methods developed in this thesis are primarily applied to ophthalmology. To provide context, we offer a concise overview of essential ophthalmological concepts that will be referenced throughout. We introduce the main retinal image modality, namely Optical Coherence Tomography (OCT), and how clinicians use it to quantify retinal thickness through the ETDRS grid. Ultimately, we demonstrate why and how deep learning can aid thousands of people when applied to ophthalmology.

\subsection{Imaging the Retina}\index{retina}\index{OCT}
The retina is located at the back of the eye, serving as the focal plane for the eye lens, as depicted in \Cref{fig:eye}. It receives the image of the visual world, and its task is to transform the incoming photons into nerve pulses. The transformation is mediated by photoreceptor cells (rods and cones) in a process that is known as \textit{visual phototransduction}. An incoming photon triggers conformational changes in the photoreceptor's membrane proteins, which begin hyperpolarization of the whole cell and, ultimately, an electrical signal\sideauthorcite{Alberts2017}. This signal travels through bipolar and ganglion cells until it finds its way through the optic nerve into the brain, where it is processed.

The organization of the photoreceptors and other retinal cells forms \textit{retinal layers}. Each one of these layers contains a distinct portion of the cells and is highly differentiated. Together, the layers that participate actively in the visual phototransduction receive the name of \textit{neurosensory retina} (NSR). Beyond the NSR, one layer is of special relevance because it nourishes the retinal cells: the retinal pigment epithelium (RPE). The formation of fluid pockets both inside the NSR layers or between the NSR and the RPE may have disastrous effects on visual acuity\sidedef{Visual Acuity}{Measure of the ability of the eye to distinguish shapes and the details of objects at a given distance~\cite{marsden2014measure}.}, as we will see later.

\textfig[t]{1}{Figures/interferometer.pdf}{Michelson interferometer. Low-coherence light is split into two beams. One is reflected by a mirror located at a known distance, while the other is sent to the retina and scattered back to the beam splitter, which combines their amplitudes. The detector detects an interference pattern.}{fig:interferometer}

For years, medical imaging methods have been developed to diagnose abnormal conditions in the organism. The eye, however, might seem unexplorable at first sight due to its soft nature and its small size, ruling out more conventional methods such as X-ray or MRI. Furthermore, any technique that scans the retina must have micrometer resolution and be able to produce cross-sectional images that reveal all the retinal layers. Optical Coherence Tomography (OCT) is a non-invasive imaging technique that combines both features. Nowadays, it is used routinely in ophthalmology to scan the retina and, in particular, the region centered at the fovea. To date, it is one of the most common imaging instruments in medicine, with over 20 million OCT scans taken each year worldwide\sideauthorcite{fujimoto2016development}.

OCT uses low-coherence interferometry. As illustrated in \Cref{fig:interferometer}, infrared light is split into two beams. One is reflected by a mirror located at a known distance, while the other is sent to the retina and scattered back to the beam splitter, which combines their amplitudes. The combined wave produces an interference pattern at the detector. This is measured to infer the properties of the retina at the scanning point. By shifting the scanning point, one can acquire a B-scan, \ie~a 2D cross-sectional image of the retina, as depicted in \Cref{fig:oct_scans} (left). A stack of ordered B-scans is known as a C-scan, \ie~a 3D representation of the retina, as shown in \Cref{fig:oct_scans} (right).

\textfig[t]{1}{Figures/oct_scans.pdf}{(Left) 2D cross-sectional image of the retina, also known as B-scan. (Right) 3D representation of the retina, or C-scan. Image partially reproduced from~\cite{Kurmann2019}}{fig:oct_scans}

\subsection{Seeing in an OCT}\index{marker}\index{IRF}\index{SRF}
OCT provides a cross-sectional view of the retina. It displays all the retinal layers with different shades of gray that depend on the layer's reflectivity\sidenote{See the retinal layers in \Cref{fig:oct_scans} as horizontal lines with different shades of gray.}. For this reason, it is the preferred imaging technique to evaluate the retinal morphology, such as its thickness or the presence of fluid\sidenote{In fact, the presence of fluid increases the retinal thickness; both properties are correlated.}. Abnormal values of these properties are directly linked to potentially disastrous eye conditions, and they are called \textit{biological markers}\sidedef{Biological Marker}{Objective indications of medical state observed from outside the patient â€“ which can be measured accurately and reproducibly~\cite{strimbu2010biomarkers}.} --- or biomarkers--- for this reason. 

The presence of fluid is of special relevance to this thesis, with \Cref{chapter:oct} diving into the methods to localize fluid pockets from OCT B-scans. More specifically, we will be interested in intraretinal and subretinal fluid (IRF and SRF, respectively):
\begin{itemize}
    \item \textbf{Intraretinal fluid (IRF)} is identified as hypo-reflective areas in the NSR layers, usually above the outer plexiform layer\sidecitation{haines2017fundamental}{The outer plexiform layer contains synapses among and between retinal photoreceptors, horizontal cells, and bipolar cells.}. It is associated with decreased visual acuity\sideauthorcite{sharma2021understanding}.

    \item \textbf{Subretinal fluid (SRF)} also appears as hypo-reflective areas in the OCT, but it is located beneath the NSR and above the RPE. The studies suggest, however, that a mild amount of SRF may be tolerated or even beneficial in terms of visual acuity\sideauthorcite{chaudhary2022association}.  
\end{itemize}

Both biological markers are associated with pathologies such as Age-Related Macular Degeneration (AMD) or Diabetic Retinopathy (DR). These pathologies affect the capillaries that nourish the retina. If they are not treated adequately, they may lead to fluid loss in the form of fluid pockets.

\subsection{Evaluating Vision: The ETDRS Grid}\index{ETDRS grid}
The quantification of the retinal morphology is only one step into the vision evaluation through OCT. Analyzing thickness data is complex, as every point of each retinal layer has one thickness value. While this enables a spatially precise evaluation of the layers, it is more meaningful in clinical practice to summarize thickness changes in larger retinal areas, effectively reducing the amount of data to analyze. Established methods for summarizing retinal thickness data utilize retinal grids centered in the macula to divide the retina into large regions of interest. These grids allow for the aggregation of thickness measurements for each region, providing a quick overview of the layers' thickness in anatomically predefined areas. 

The most common grid type for retinal thickness aggregation was introduced by the Early Treatment Diabetic Retinopathy Study (ETDRS)\sideauthorcite{early1991grading} and is known as the ETDRS grid. It divides the retina into nine regions defined by three rings centered around the fovea: a \qty{1}{\milli\metre}-diameter central ring, an inner macular ring with \qty{3}{\milli\metre} diameter, and an outer macular ring with \qty{6}{\milli\metre} diameter. Furthermore, the 3 and \qty{6}{\milli\metre} rings are divided into four quadrants: nasal, temporal, superior, and inferior. The retinal thickness is averaged for all the points in a region so that only one value is stored. Figure \Cref{fig:etdrs}, from \yeartextcite{rohlig2019enhanced}, illustrates the ETDRS grid in a coronal plane located at the retina (a and b), and in a transverse plane that passes through the fovea (c and d). 

\textfig[t]{1}{Figures/etdrs.png}{ETDRS grid. (a, b) It divides the retina into nine regions defined by three rings centered around the fovea. (c) A B-scan with an overlain ETDRS grid. (d) Layer thickness quantification. Figure from \cite{rohlig2019enhanced}.}{fig:etdrs}

The aggregation of thickness data in predefined regions facilitates the tracking of progressive diseases while considering the natural variations of the retina. This aspect has been crucial for the rapid spread of the ETDRS grid for disease assessment, as the different ETDRS ring regions are linked to different visual function levels. 

\subsection{Merging Deep Learning and Ophthalmology}
Early diagnosis and treatment of ocular diseases are key to slowing down the progress of symptoms, and OCT is the preferred diagnostic tool to image the retina due to its safety and quickness. However, every year, around 30 million OCT retinal scans are acquired and processed, and clinics are running out of experts to interpret them. These experts use biological markers to assess the presence of several conditions. Still, the variety in shape, size, and extent of said markers makes even their coarse location a paramount task. On the other hand, deep learning models are becoming faster and more capable, showing on-par performance compared to humans in some tasks\jgt{cite}. The marriage of both worlds seems, therefore, inevitable. 

Nevertheless, the introduction of AI methods into a medical field, such as ophthalmology, must be done carefully and respectfully. Several methods have been proposed in recent years that see the problem only from one side\sidenote{Usually, that side is computer science}  and therefore lack the general view that clinicians have acquired over years of practice, errors, and successes. This is the case of \yeartextcite{gulshan2016development}, a work that compared an automated deep learning algorithm against manual grading by ophthalmologists for diabetic retinopathy in retinal fundus photographs\sidedef{Retinal Fundus Photograph}{Medical image captured of the interior surface of the eye, including the retina, optic disc, and macula.}. After achieving promising results on diabetic retinopathy datasets, the system received official medical device certification and was deployed in India and Thailand\sideauthorcite{google2019retina}. Despite the previous encouraging results, the system faced significant challenges in deployment, mainly due to data quality\sideauthorcite{widner2023lessons}.
