% Domain Adaptation in Computer Vision
%   Why DA is important --> Start with an example in medical imaging, add a picture to show everything
%   The amount of information determines the flavor: Types of Domain Adaptation (Unsupervised, source free...)
%   Domain Adaptation in Real-World Applications  ---> Probably not!

\section{Domain Adaptation}\label{sec:domain_adaptation}\index{domain adaptation}

\textfig[b]{1}{Figures/domain_adaptation_example.pdf}{\jgt{TODO}}{fig:domain_adaptation_example}

\Cref{fig:domain_adaptation_example} shows brain MRI scans from three sites with the same acquisition type. At the same time, \Cref{fig:domain_adaptation_intensity} \jgt{shows} a quantification of the pixel intensity distribution per site normalized within that site. Both figures suggest that image values are not only dependent on the field of application\sidenote{Of course, the pixel distribution of road images acquired for self-driving cars and that of brain MRIs will be completely different.}, nor on the acquisition type, but also on the particular settings defined on-site. This poses a critical problem for computer vision: how to build models that bridge the domain shift\sidenote{See \Cref{subsec:da_intro}, where this term was introduced.}, \ie~that generalize data with the same semantic distribution but different features. For example, in \Cref{fig:domain_adaptation_example}, all three images have the same semantic information (brain MRIs with white matter hyperintensities), but the images' features are very different. We say in this case that the source domain\sidedef{Source Domain}{\jgt{TODO}} --- the initial domain on which the model is trained --- is different from the target domain\sidedef{Target Domain}{\jgt{TODO}} --- the domain to which we are applying the model.

\textfig[t]{1}{Figures/domain_adaptation_intensity.pdf}{\jgt{TODO}}{fig:domain_adaptation_intensity}

In this section, we will explore how the field of Domain Adaptation is searching for the answer to the previous question. We will see that the answer depends on the amount of information in both the source and the target domains during training and how the complexity of the problem increases as this variable decreases.

\subsection{The Amount of Information Determines the Flavor}
Just as the presence or absence of labels categorizes the learning paradigms, it also categorizes the different types of domain adaptation. However, the presence of two domains introduces a certain degree of complexity. For instance, one may have no source domain images available, yet a few target labels and a substantial number of target images. When developing a domain adaptation model, it becomes crucial to ascertain the scenario at hand, as the techniques employed will vary. Nevertheless, all techniques and domain adaptation paradigms aim to construct a domain invariant representation or utilize information from the source domain in the target. 

\Cref{fig:domain_adaptation_cube} depicts a conceptual model of the learning paradigms, wherein the number of unlabeled source images and labeled and unlabeled target images serve as the axes\sidenote{A representation of all the learning paradigms requires one more dimension. I had trouble representing four dimensions in a 2D paper, so I had to discard one of them.}. It can be observed that not having target labels is common, as it otherwise becomes either semi-supervised or supervised learning. Additionally, there are two scenarios that only differ in the number of target images (source-free and test-time domain adaptation) and one where no target images are available (self-supervised learning).

\subsubsection{Semi-Supervised Domain Adaptation} Very similar to traditional semi-supervised learning\sidenote{See \nameref{subsec:semi_self} in \Cref{sec:training_paradigms}.}. What defines this category is the presence of some labeled target images and a larger amount of unlabeled ones. Training strategies do not differ significantly from those used for semi-supervised learning, using the unlabeled samples for feature alignment and a regularization term that leverages the labeled samples.

\subsubsection{Unsupervised Domain Adaptation} 

\subsubsection{Source-Free Domain Adaptation}

\subsubsection{Test-Time Domain Adaptation}