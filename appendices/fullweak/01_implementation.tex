\section{Implementation details}
\label{sec:impl}
{\bf Weakly-supervised segmentation model hyperparameters: }
We used the U-Net segmentation model~\cite{ronneberger2015u} for OCT, and the DeepLabV3 model~\cite{chen2017rethinking} with a ResNet50 backbone on the SUIM, PASCAL, and Cityscapes datasets. For the U-Net, a classification head with max-avg pooling and one fully connected layer was appended at the end of the encoding module for the classification task. For the DeepLab-like models, we trained the entire ResNet-50 backbone on the classification task and then added the ASPP head for segmentation. In all cases, we used the cross-entropy loss for classification and the average of the Dice and cross-entropy losses for segmentation. \cref{tab:configurations_model} contains the details of batch sizes and optimizers.

\begin{table}[h]
\centering
\begin{tabular}{lcccccc}
\toprule
\textbf{Dataset} & \textbf{Model} &  \textbf{Optimizer} & \textbf{Batch size} \\ \midrule
\textbf{OCT} & U-Net &  Adam & 8  \\
\textbf{VOC} & DeepLabV3 &  SGD & 16 \\
\textbf{SUIM} & DeepLabV3 &  SGD & 8  \\ 
\textbf{Cityscapes} & DeepLabV3 & SGD & 16   \\ \bottomrule
\end{tabular}
\caption{Hyperparameters and conditions for all experiments.}
\label{tab:configurations_model}
\end{table}

{\bf Algorithm hyperparameters: }
We measured the costs of annotations in terms of class-label equivalents setting~$\alpha_c=1$ and leaving only $\alpha_s$ as a hyperparameter of our method. We set to~$\alpha_s=12$ for all datasets following previous studies on crowdsourced annotations~\cite{Bearman16}. We fixed the number of iterative steps to~$T=8$ and the learning rate of the GP to~$0.1$. We set both the initial number of class annotations~$C_0$ and segmentation annotations~$S_0$ to~$8\%$ of the available labels for SUIM and Cityscapes. We reduced $C_0$~in OCT and $S_0$~in VOC to account for the higher number of labels available in those datasets, as detailed in~\cref{tab:configurations_gp}.

\begin{table}[h]
\centering
\begin{tabular}{lcccccc}
\toprule
\textbf{Dataset} & $C_0 (\%)$ & $S_0 (\%)$ & $B_0$ \\ \midrule
\textbf{OCT} & 4 & 8 & 1'774 \\
\textbf{VOC} & 8 & 6 & 8'076 \\
\textbf{SUIM} & 8 & 8 & 1'586 \\ 
\textbf{Cityscapes} & 8 & 8 & 1'774  \\ \bottomrule
\end{tabular}
\caption{Initial conditions for our method. $B_0$ calculated with $\alpha_s = 12$ and $\alpha_c = 1$.}
\label{tab:configurations_gp}
\end{table}
