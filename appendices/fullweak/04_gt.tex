\section{Ground-truth approximation}
\label{sec:gt}
To address the high computational demands of our experiments, we followed the procedure of~\cite{mahmood2022optimizing} for ground-truth approximation. 
In particular, we built subsets of the training dataset by randomly sampling different proportions of the available annotated samples~\cite{mahmood2022}. The proportions~$\rho_s$ and~$\rho_c$ for segmentation and classification samples, respectively, were chosen from the set~$\{2\%, 4\%,	6\%, 8\%, 10\%, 20\%, 30\%, 40\%, 60\%, 80\%, 100\%\}$, for a total of $11\times{}11=121$~possible training subsets. For each subset, we trained the weakly-supervised segmentation model and measured its Dice score on a fixed segmentation test set. We finally interpolated these scores with third-order splines to obtain a surface of ground-truth Dice scores. This procedure allowed efficient estimations of the Dice Score values without retraining a new model for each strategy.

The proportions~$\rho_s$ and~$\rho_c$ are relative to the total amounts of available annotated samples in each dataset, which are shown in \cref{tab:datasets}.

% \subsection{Data collection}


\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Dataset} & \textbf{Segmentation} & \textbf{Classification} \\ \hline
\textbf{OCT} & 902 & 22'723 \\
\textbf{VOC} & 10'582 & 5'717 \\
\textbf{SUIM} & 1'525 & 1'525 \\
\textbf{Cityscapes} & 2'975 & 2'975 \\ \hline
\end{tabular}
\caption{Number of training images for each dataset and modality.}
\label{tab:datasets}
\end{table}
