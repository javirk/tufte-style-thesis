% Labeling: 
%   Adaptive strategy, with a mean dependent on the surface. 
%   Application to more types of labels.
%   Application to the same type of annotations but with different levels of expertise
%   Automated labeling 

\section{Improve Labeling to Reduce Data Dependency}
An objective assessment of a current technique's limitations may sprout new avenues for research. \Cref{chapter:fullweak} proposed a method for online budget-aware data labeling, and the results already pointed in a direction for future work. In the first place, we identified that our method was greedy. Secondly, we assumed that segmentation performance increases logarithmically with the volume of data. This assumption, backed by previous research\sideauthorcite{sun2017}, was utilized to set the mean prior for the GP, a fundamental piece of the algorithm. Even if it is unclear whether this asymptotic logarithmic trend assumption is violated for one of the evaluation datasets, we believe that some additional learnable parameters should be added to the mean prior to reflect the bizarre behavior of this dataset. Out of the four, this is the only dataset in which the rates of performance improvement\sidenote{For segmentation and classification.} increase with the number of samples. Our method is not equipped with anything to face this situation, hence its failure.

Furthermore, there is an immediate following for this work that might prove interesting. Even if the method should be agnostic to the annotation type, both for weak and full, studying its behavior with other combinations could be fruitful in understanding which annotation types are more cost-efficient. Aside from this, an expansion to more dimensions, say image-wise classification labels, bounding boxes, and segmentation labels altogether, would only be a challenge in computing power. The combinations in this scenario would grow exponentially with respect to the 2D case that we proposed.

Another interesting line of work related to annotation strategies involves the integration of synthetic labels into the game. The recent advancements in computer graphics are permeating the computer vision field by introducing increasingly realistic synthetic datasets. Synthetic data allows for a more controlled and predictable environment, which greatly simplifies the labeling process\sidenote{For instance, acquiring normal maps in natural data requires depth estimation. In synthetic data, they come naturally from the scene.}. Furthermore, generated images can provide the model with scenarios that are difficult to retrieve, such as dangerous situations for self-driving or highly rare medical conditions. However, whether a model can be fully trained from synthetic data remains unclear. Therefore, the combination of natural and synthetic data will likely yield the best results. Determining the optimal ratio will be challenging, but I anticipate that methods similar to those presented in this work will play a key role in this field. 

I have reiterated in this thesis the significant investment required to acquire expert annotations. Nevertheless, it can be argued that no two experts are identical. Individuals who have undergone professional training and possess considerable experience are typically compensated more than those who have recently graduated. Conversely, it is assumed that the former group possesses greater knowledge than the latter due to their experience. This could be modeled in a similar framework to that described in \Cref{chapter:fullweak}, where the labeling modality combination would be between senior and junior annotators, with a non-unitary cost ratio. Domain knowledge and experience could be incorporated by introducing noise to one of the axes.  
