% Continual generalization?
%   Preventing forgetting
%   Test-time

\section{Generalizing Models}\index{catastrophic forgetting}
Current domain adaptation networks often face the significant challenge of not retaining information about the source domain, leading to a phenomenon known as catastrophic forgetting. If we strive to have AI assistants more present in routine tasks, it is imperative to develop advanced continual learning techniques that enable models to maintain and integrate knowledge from all domains seamlessly. Image acquisition devices will improve, leading to higher-resolution images with better contrast. However, the intrinsic knowledge of deep learning models should be maintained. One-year-old kids can discern a lion from a tiger on TV even if they have seen only drawings of them, and this is because they know what a lion \textit{is} and not only how it \textit{looks}. Artificial intelligence models should be capable of generalizing and adding knowledge to what they already \textit{know}. The traditional trend of training larger models from scratch every few months is not sustainable and will become obsolete in the short to medium term. Resources should be invested in researching alternatives to this paradigm.

In this regard, test-time domain adaptation methods offer an intermediate solution because they let the model work on a prediction and determine if that is the best prediction it can produce. As contrary as I am to the anthropomorphization of deep learning models and their identification with the human brain, I think it is reasonable to think of test-time domain adaptation algorithms in terms of the thought process we humans do when we are exposed to novel information. Without realizing it, our brain processes and works on the information, not letting the first thing that comes to be deployed through our mouth. Test-time algorithms work in this direction. Therefore, I believe they will gain popularity in the future.

In this line, I believe applying reinforcement learning-like techniques to computer vision, as it is done nowadays to natural language processing, will become beneficial. Segmentation models can already estimate how accurate their predictions are with high precision. Hence, this information could be used as self-supervision for the next iteration. Of course, the space of semantic segmentations is much more varied than a vocabulary, given the amount of pixels in an image. At the same time, the possible valid segmentations are less varied than valid sentences one can generate from a prompt. Generating varied predictions such that exploration is done in a meaningful way is, therefore, a complicated task. 