\section{Conclusion}
\label{sec:conclusion}
In this work, we propose a SAM Decoder Adapter for semantic segmentation that introduces negligible overhead. We achieve this by using a lean approach, using the image embeddings in the decoder as queries in the attention modules of the adapter, and combining the result before the next two-way attention layer. We outperform the mask prediction quality of state-of-the-art methods and show that zero-shot generalization capabilities are improved. Furthermore, we evaluate our method on a more challenging task, Test-Time Domain Adaptation, and show its superiority against other large model adapters. With extensive ablation studies, we explain the design choices behind this simple yet powerful adapter.
