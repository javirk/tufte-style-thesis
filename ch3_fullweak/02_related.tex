\section{Related work}
\label{sec:related}

\subsection{Weak annotations for segmentation}
\autoindex{Weakly supervised semantic segmentation} (WSSS) relies on coarser annotations, such as bounding boxes~\sidecite{song2019box}, scribbles~\sidecite{lin2016scribblesup,tang2018normalized} or image-level classification labels~\sidecite{ahn2019weakly}, to train a segmentation network. WSSS methods have often employed saliency maps as weak annotations for segmentation models, as these are typically obtained from CAM~\sidecite{zhou2016learning}, which leverages image-level classification annotation. These methods then focus on refining the saliency maps with a variety of techniques~\sidecite{fan2020learning,lee2019ficklenet}. Others make use of attention to achieve coarse segmentations~\sidecite{jiang2019integral,Ki2021}. Conversely, \yeartextcite{Zhang2021} combined annotations in the form of bounding boxes and image-level labels to accurately generate image graphs, to be used by a graph neural network to predict node values corresponding to pixel labels. In this context, the work in~\yeartextcite{mahmood2022} and~\yeartextcite{mahmood2022optimizing} are close to this one, whereby their objective is to determine what annotation strategy over annotation types is likely to yield a target performance level. 

\subsection{\autoindex{Transfer learning}}
Due to the limited availability of annotated image data in some domains, it is now common to use neural networks pre-trained on large image classification tasks~\sidecite{deng2009imagenet} for subsequent target tasks. Specifically, in cases where the target task has limited data or annotations, this has been shown to be particularly advantageous. Among others, this practice is now widely used in medical imaging and has been linked to important performance gains after fine-tuning~\sidecite{Esteva2017,menegola2017,Tajbakhsh2016}.

Efforts are now pivoting towards the use of in-domain pre-training, avoiding the leap of faith that is often taken with Imagenet~\sidecite{heker2020joint}. In \yeartextcite{Liang2020}, the model is pre-trained on ChestX-ray14~\sidecite{wang2017chestxray} to more accurately detect pneumonia in chest X-ray images from children. In~\yeartextcite{heker2020joint}, the authors show that joint classification and segmentation training, along with pre-training on other medical datasets that have domain similarity, increases segmentation performances with respect to the segmentation using Imagenet-based pre-training.

Alternatively, cross-task methods seek to transfer features learned on one task (\eg~ classification, normal estimation, etc.) to another, usually more complex one. Along this line, Taskonomy~\sidecite{zamir2018taskonomy} explored transfer learning capabilities among a number of semantic tasks and built a task similarity tree that provided a clustered view of how much information is available when transferring to other tasks. Similarly,~\yeartextcite{Mensink} performed an extensive study of cross-task transfer capabilities for a variety of datasets, reaching the conclusion that Imagenet pre-training outperforms random initialization in all cases, but further training on related tasks or domains also brings additional benefits.

\subsection{\autoindex{Active learning}}
In active learning, the goal is to train a model while querying an oracle to label new samples that are expected to improve the model's accuracy. In computer vision, it has been applied to image classification~\sidecite{Joshi2009,Ranganathan2017} or semantic segmentation~\sidecite{andriluka2018fluid,Benenson2019LargeScaleIO,siddiqui2020viewal} among others. As a byproduct, Active learning has also been used as a way to reduce labeling time. For example,~\yeartextcite{Konyushkova_2018_CVPR} describes a method that couples Reinforcement Learning and Active Learning to derive the shortest sequence of annotation actions that will lead to object detection within an image. Others have focused on speeding up this process via eye-tracking~\sidecite{papadopoulos2014} or extreme clicking~\sidecite{papadopoulos2017extreme}. As such, Active Learning is related to the present work in the sense that our approach is adaptive but differs in that our method determines what annotations types should be collected under a constrained budget instead of predicting at each time step which samples should be added to the annotated set.