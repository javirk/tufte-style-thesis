% Weak labels for a real-world problem
\section{Weak Labels and Domain Knowledge for a Real-World Problem}\label{sec:disc_oct}

The last sections have covered data acquisition and model adaptation, but \Cref{chapter:oct} focused on a problem closer to a real-world application. Reading Centers\sidedef{Reading Center}{Facility that evaluates and interprets retinal images for clinical trials and studies.} across the world work tirelessly to classify thousands of ophthalmic images. They screen one image after another to find biological markers for potential malignant conditions in patients following clinical trials. Their employees are specifically trained for this purpose, and most of their work is manual. AI could alleviate the laborious screening task, and serve as a triage for those images that do not require a human expert to review them. With a growing and ever-older population, the number of ophthalmic images is only going to increase in the foreseeable future. Automatic detection methods will, at that point, be of invaluable help.

\Cref{chapter:oct} was our effort to ease this problem in OCTs. We proposed a method that located biological markers in ETDRS rings, requiring only weak labels in the form of slice-level binary annotations of marker presence during training. This way, we avoided the need for expensive segmentation annotations. During testing, our method inferred marker presence and location in ETDRS rings. We achieved this via two combined mechanisms: first, we realized that the conversion from localization within an image to an ETDRS ring was a mere post-processing step that depended solely on the slice position within the C-scan. Accordingly, we pooled each image's feature map in columns, preserving spatial relations. Each one of these columns was classified independently with the same MLP. At the end, we performed the post-processing step, converting the column predictions into ETDRS rings.

On the other hand, we enforced geometrically and biologically plausible solutions with a tailored loss function. The previous column classification, combined with slice-level annotations, gave enough information about the location of the markers. When a marker was not present---\ie~its label was negative---it could not be present in any of the columns. At the same time, if a marker was present---\ie~its label was positive---it had to be present in at least one of the columns. 

We tested our method and compared it against a range of alternative approaches. In general, our method consistently outperformed the benchmark alternatives across all marker and ETDRS ring combinations. This supported our hypothesis that feature maps can be effectively utilized to identify marker locations at a coarse level. Moreover, we assessed the efficacy of our method prior to the post-processing step with the \textit{en face} projection\index{en face projection}, showing positive results.

With the same purpose of alleviating the need for strong annotations, in \Cref{chapter:regional_mosaics} we propose a method to produce a map of the geological lineaments\sidedef{Geological Lineament}{Any extensive linear feature on a planetâ€™s surface that can be identified when there is a change in the topographical data. Definition adapted from~\cite{arifin2021geological}.} of the surface of Jupiter's satellite Europa. This method utilizes coarsely annotated data during inference to provide a lineament map that can be later employed to assess the geological properties of the surface. 

\Cref{chapter:oct} built on the conclusions drawn in the previous section. We see that weak annotations are sometimes sufficient to achieve meaningful results, provided that other characteristics of the data or the domain are taken into account. This reiterates a previous idea: weak annotations are more cost-effective to retrieve, allowing an equivalent budget to access a greater quantity. Their significance should not be disdained, as deep learning models benefit from exposure to a diverse range of data samples that cover a broad distribution.