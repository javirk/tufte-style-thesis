\section{Discussion}

The proposed method achieved satisfactory results in all ETDRS rings and studied biological markers. Our method outperforms the compared baselines for every marker and ETDRS ring, confirming our hypothesis that feature maps can be used to coarsely identify marker locations.

We note, however, that, in terms of AP, the prediction performance for SRF in the 3mm and 6mm rings is significantly lower than other reported values for all methods. As discussed in the Results section, it is unlikely to find SRF in the outer rings, leading to a lower number of occurrences of this biological marker\sidenote{As noted in \Cref{tab:results}, only 0.4\% of the slices contain SRF in the 6mm ring, as opposed to 38.4\% for IRF.}. This in turn strongly reduces the precision of the methods as soon as there are just a few false positive detections. The associated AUC ROC scores do not exhibit this behavior since they include false positive rates.

The segmentation results in \Cref{tab:segmentation_results} show that the proposed method is robust even before our post-processing mapping for coarse biomarker localization, meaning that the post-processing step is transparent to the performance of the model. 

The ablation studies in \Cref{tab:ablation_loc} suggest that not only is the architecture itself important ($\ell_1$) but so is enforcing coherence in the column outputs with the slice labels (i.e. $\ell_2$). In the case of SRF at 3mm and 6mm, this provides a significant performance increase without reducing the performances of other outputs. For SRF, AP increases by 41.2\% at 3mm and 43.4\% at 6mm, while close to no difference is seen for IRF, where the results with $\ell_1$ already outperform some of the baselines. This boost at the outer rings is highly beneficial as the presence of biological markers in these rings (especially SRF) is highly scarce, therefore making it harder to train appropriately for. In our testing dataset, acquired with a variety of eyes and patients, only 113 out of 28â€™322 B-Scans showed SRF in the 6mm ring. Finally, including $\ell_3$ brings modest but consistent gains when $\ell_1$ and $\ell_2$ are already used.

Compared to other methods, our model is more robust than the baselines, giving more reliable results even in hard situations where previous methods struggle. Grad-CAM is the go-to method in virtually all weakly supervised segmentation methods for OCT, which rely on a CAM-based approach with various architectures. In this line, MS-CAM~\sidecite{ma2020} proposes an architecture that leverages the activations of the different feature resolutions of the backbone and then combines them with Grad-CAM++. Segmentations are then refined using CRF on the en-face projection image. For a fair comparison with our method, which does not use C-Scan information, we implemented only the first stage. The results in \Cref{tab:results} show a performance worse than other baselines, with a strong difference in more difficult scenarios. For SRF at the 6mm ring, MS-CAM achieves 1.6 AP, compared to 19.1 with our method. We believe that CRF refinement plays a major role in MS-CAM by reducing the over-segmentation produced by the first stage. Over-segmentation leads to false positive predictions in our set-up, which reduces Average Precision.

Szeskin et al.~\sidecite{Szeskin2021} use vertical pixel-wide columns in OCT slices to classify atrophic regions. Each B-Scan is partitioned into columns and fed with contiguous slices into a convolutional neural network, which outputs a binary label. The results are projected onto the infrared imaging image and are used to identify and segment atrophy lesions. Although this work looks similar to ours, it differs in the training scheme: while we only use slice-level annotations, allowing us for independent coarse segmentation per slice; the method proposed by Szeskin et al.~\sidecite{Szeskin2021} uses per volume labeling in the form of IR image segmentation.
Schlegl et al.~\sidecite{Schlegl} focuses on voxel-wise segmentation and, while their output could be used for location as well, the method differs in intent and uses voxel-wise ground truth labels to train. Because our method uses only 2D slices and much weaker annotations, we believe it is not a comparable baseline.

Finally, the analysis of the en-face projection and segmentation results in \Cref{tab:segmentation_results}, as well as \Cref{fig:bland_altman} and \Cref{fig:correlation}, shows two aspects: 1) The outperformance of our model over the baselines does not depend on the post-processing step and 2) although both the training and inference act per B-Scan, the method is reliable and consistent when applied to all the slices in a volume. The Bland-Altman plot in Figure 8, along with the correlation plot in \Cref{fig:correlation}, show that our area predictions per volume strongly agree with the Expert segmentation in the case of IRF. For SRF, this task remains challenging, and our method tends to underestimate the en-face area, as proved by the slope of 0.30 in the linear regression and the corresponding Bland-Altman plot. However, the end goal of our method is not to have an accurate segmentation of the en-face, but it comes as a byproduct.

We demonstrated that slice-level labels are sufficient to locate biological markers in ETDRS rings for OCT scans if weak constraints are enforced on the loss function. Furthermore, we confirmed that it is possible to modify the pooling strategy of a standard convolutional network to perform coarse localization without annotations. The method has proven to be more reliable than other baselines, even in hard situations where the number of training samples is scarce, as shown in \Cref{tab:results}. The ablation experiments in \Cref{tab:ablation} demonstrate that the new terms in the loss function, especially $\ell_2$, are key to the performance of the model, producing consistent gains in all scenarios. Moreover, even if our method has only been presented with individual B-Scans during training, with no sense of complete volumes, it is capable of outputting volume-wise consistent predictions, as depicted in the segmentation and en-face projection results (\Cref{tab:segmentation_results} and \Cref{tab:en_face} respectively). Lastly, there is no constraint in the loss function with regard to the markers that can be located. Therefore, the described approach could potentially be used to locate any biological marker as long as class labels are available.

\subsection{Limitations}
Our approach has some limitations. Most notably, the granularity of the output before post-processing is constrained by the resolution of the feature maps. A more granular output would most likely improve the precision of the method. However, achieving such high-resolution feature maps collides with the main intention of classification neural networks, which are conceived to reduce the dimensionality of the inputs before the final linear layer. Another limitation comes from the variety of biological markers that have been tested. Due to labeling capacity and present pathologies in the data, only IRF and SRF were tested. Although the proposed method is agnostic to this aspect and potentially should behave equally with a larger cohort of markers, a more detailed study is required to confirm it.
